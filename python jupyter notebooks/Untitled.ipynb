{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization,AveragePooling2D,Convolution2D\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import MaxPool2D\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_images = []       \n",
    "train_labels = []\n",
    "shape = (200,200)  \n",
    "train_path = \"C:/Users/panur/facedetection/data/train\"\n",
    "\n",
    "for filename in os.listdir(train_path):\n",
    "    for images in os.listdir(\"C:/Users/panur/facedetection/data/train/\"+filename):\n",
    "        \n",
    "        img = cv2.imread(train_path+\"/\"+filename+\"/\"+images)\n",
    "        \n",
    "        # Spliting file names and storing the labels for image in list\n",
    "        train_labels.append(filename)\n",
    "        \n",
    "        # Resize all images to a specific shape\n",
    "        img = cv2.resize(img,shape)\n",
    "        \n",
    "        train_images.append(img)\n",
    "\n",
    "\n",
    "# Converting labels into One Hot encoded sparse matrix\n",
    "train_labels = pd.get_dummies(train_labels).values\n",
    "\n",
    "# Converting train_images to array\n",
    "train_images = np.array(train_images)\n",
    "\n",
    "# Splitting Training data into train and validation dataset\n",
    "x_train,x_val,y_train,y_val = train_test_split(train_images,train_labels,random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_labels = []\n",
    "shape = (200,200)\n",
    "test_path = \"C:/Users/panur/facedetection/data/validation\"\n",
    "for filename in os.listdir(test_path):\n",
    "    for images in os.listdir(\"C:/Users/panur/facedetection/data/validation/\"+filename):\n",
    "        \n",
    "        img = cv2.imread(test_path+\"/\"+filename+\"/\"+images)\n",
    "        \n",
    "        # Spliting file names and storing the labels for image in list\n",
    "        test_labels.append(filename)\n",
    "        \n",
    "        # Resize all images to a specific shape\n",
    "        img = cv2.resize(img,shape)\n",
    "        \n",
    "        test_images.append(img)\n",
    "        \n",
    "# Converting test_images to array\n",
    "test_images = np.array(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(200,200,3)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# output layer\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(200,200,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(36, (5, 5)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(48, (5, 5)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(500, activation=\"relu\"))\n",
    "model.add(Dense(90, activation=\"relu\"))\n",
    "model.add(Dense(20, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=categorical_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_40 (Conv2D)           (None, 198, 198, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 198, 198, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 99, 99, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 95, 95, 36)        28836     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 95, 95, 36)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 47, 47, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 43, 43, 48)        43248     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 43, 43, 48)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 21, 21, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 19, 19, 64)        27712     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 500)               1568500   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 90)                45090     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 20)                1820      \n",
      "=================================================================\n",
      "Total params: 1,753,030\n",
      "Trainable params: 1,753,030\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3794 samples, validate on 1265 samples\n",
      "Epoch 1/10\n",
      "3794/3794 [==============================] - 176s 46ms/step - loss: 1.6330 - accuracy: 0.7119 - val_loss: 0.0409 - val_accuracy: 0.9905\n",
      "Epoch 2/10\n",
      "3794/3794 [==============================] - 179s 47ms/step - loss: 0.0161 - accuracy: 0.9966 - val_loss: 4.2922e-04 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "3794/3794 [==============================] - 178s 47ms/step - loss: 2.0295e-04 - accuracy: 1.0000 - val_loss: 3.1739e-05 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "3794/3794 [==============================] - 178s 47ms/step - loss: 2.9469e-05 - accuracy: 1.0000 - val_loss: 1.7461e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "3794/3794 [==============================] - 178s 47ms/step - loss: 1.9400e-05 - accuracy: 1.0000 - val_loss: 1.2718e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "3794/3794 [==============================] - 180s 47ms/step - loss: 1.4695e-05 - accuracy: 1.0000 - val_loss: 1.0005e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "3794/3794 [==============================] - 204s 54ms/step - loss: 1.1638e-05 - accuracy: 1.0000 - val_loss: 8.0655e-06 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "3794/3794 [==============================] - 178s 47ms/step - loss: 9.6957e-06 - accuracy: 1.0000 - val_loss: 6.7823e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "3794/3794 [==============================] - 181s 48ms/step - loss: 8.1894e-06 - accuracy: 1.0000 - val_loss: 5.8150e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "3794/3794 [==============================] - 214s 56ms/step - loss: 6.9069e-06 - accuracy: 1.0000 - val_loss: 4.9486e-06 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20880eb26c8>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=10,batch_size=64,validation_data=(x_val,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing predictions and the actual label\n",
    "checkImage = test_images[0:1]\n",
    "checklabel = test_labels[0:1]\n",
    "\n",
    "predict = model.predict(np.array(checkImage))\n",
    "\n",
    "print(\"Actual :- \",checklabel)\n",
    "print(\"Predicted :- \",np.argmax(predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual :-  ['withmask_1602-18-737-006_0.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_10.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_102.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_107.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_112.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_116.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_121.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_126.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_131.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_135.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_141.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_144.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_147.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_15.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_151.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_154.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_157.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_161.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_168.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_174.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_178.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_183.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_188.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_19.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_192.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_197.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_202.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_206.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_211.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_216.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_22.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_221.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_227.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_229.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_237.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_24.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_240.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_244.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_250.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_28.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_33.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_37.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_4.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_42.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_47.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_48.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_52.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_56.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_62.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_65.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_70.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_72.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_76.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_81.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_84.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_87.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_91.jpg']\n",
      "Predicted :-  0\n",
      "Actual :-  ['withmask_1602-18-737-006_99.jpg']\n",
      "Predicted :-  0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i in range(len(test_images)):\n",
    "    checkImage = test_images[i:i+1]\n",
    "    checklabel = test_labels[i:i+1]\n",
    "\n",
    "    predict = model.predict(np.array(checkImage))\n",
    "    print(\"Actual :- \",checklabel)\n",
    "    print(\"Predicted :- \",np.argmax(predict))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"fer_json = model.to_json()\n",
    "with open(\"fer.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "model.save_weights(\"fer.h5\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "#load model\n",
    "model = model_from_json(open(\"fer.json\", \"r\").read())\n",
    "#load weights\n",
    "model.load_weights('fer.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []\n",
    "test_labels = []\n",
    "shape = (200,200)\n",
    "test_path = \"C:/Users/panur/Downloads/test/\"\n",
    "for filename in os.listdir(test_path):\n",
    "    for images in os.listdir(\"C:/Users/panur/Downloads/test/\"+filename):\n",
    "        \n",
    "        img = cv2.imread(test_path+\"/\"+filename+\"/\"+images)\n",
    "        \n",
    "        # Spliting file names and storing the labels for image in list\n",
    "        test_labels.append(images)\n",
    "        \n",
    "        # Resize all images to a specific shape\n",
    "        img = cv2.resize(img,shape)\n",
    "        \n",
    "        test_images.append(img)\n",
    "        \n",
    "# Converting test_images to array\n",
    "test_images = np.array(test_images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
